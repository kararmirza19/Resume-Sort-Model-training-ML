import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer
from warnings import filterwarnings
filterwarnings('ignore')
import re



data = pd.read_csv("/content/UpdatedResumeDataSet.csv")
data.head()

"data set link https://www.kaggle.com/datasets/gauravduttakiit/resume-dataset"

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

frame = data['Category'].value_counts().reset_index()
frame

data.describe()


data.info()
data.shape

sns.barplot(x='count', y='Category', data=frame)


def clean(txt):
    txt = re.sub('http\S+\s*', ' ', txt)  # remove URLs
    txt = re.sub('RT|cc', ' ', txt)  # remove RT and cc
    txt = re.sub('#\S+', '', txt)  # remove hashtags
    txt = re.sub('@\S+', '  ', txt)  # remove @mentions
    txt = re.sub('[%s]' % re.escape("""!"#$%&'()*+,-./:;<=>?@[\]^_`{|}~"""), ' ', txt)  # remove punctuations
    txt = re.sub(r'[^\x00-\x7f]',r' ', txt)
    txt = re.sub('\s+', ' ', txt)  # remove extra whitespace
    return txt


data['cleaned'] = data['Resume'].apply(lambda x: clean(x))
data.head()


label = LabelEncoder()
data['Category'] = label.fit_transform(data['Category'])
data

txt = data['cleaned'].values
target = data['Category'].values
word_vectorizer = TfidfVectorizer(
    sublinear_tf=True,
    stop_words='english',
    max_features=1500)
word_vectorizer.fit(txt)
WordFeatures = word_vectorizer.transform(txt)

WordFeatures


X_train, X_test, y_train, y_test = train_test_split(WordFeatures, target, test_size=0.2, random_state=42)

print(f"X_train { X_train.shape}")
print(f"X_test { X_test.shape}")
print(f"y_train { y_train.shape}")
print(f"y_test { y_test.shape}")



from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report

from sklearn.neighbors import KNeighborsClassifier
knn_classifier = KNeighborsClassifier()


param_grid = {'n_neighbors' : [3,5,7,8]}

from sklearn.model_selection import GridSearchCV
search = GridSearchCV(knn_classifier, param_grid, cv=5, scoring='accuracy')
search.fit(X_train, y_train)


knn_classifier = KNeighborsClassifier()

params = search.best_params_
score = search.best_score_

knn_classifier.fit(X_train, y_train)


y_pred = knn_classifier.predict(X_test)
class_report = classification_report(y_test, y_pred)
print("Best Parameters:", params)
print("Best Score (CV Accuracy):", score*100)
print(class_report)

from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score

models = {
    'LogisticRegression': LogisticRegression(),
    'MultinomialNB': MultinomialNB()
}


accuracy_scores = {}

for mod_name, model in models.items():
    model.fit(X_train, y_train)

    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    accuracy_scores[model_name] = accuracy


    print(f'Accuracy of {mod_name} on test set: {accuracy:.2f}')

from sklearn.feature_extraction.text import TfidfVectorizer
tfidf = TfidfVectorizer(stop_words='english')

tfidf.fit(data['Resume'])
required_txt = tfidf.transform(data['Resume'])
required_txt


